"""
LLM 기반 백엔드 KPI 직접 평가 모듈.

Few-shot Learning을 활용하여 이력서 텍스트에서 
백엔드 개발자 KPI 10개에 대한 점수를 직접 산출.
"""
from typing import Dict
from openai import OpenAI
import json

from app.core.config import settings


# KPI 정의 및 평가 기준
KPI_DEFINITIONS = """
## BE KPI 10개 및 평가 기준

아래 예시는 **"기준표"** 역할을 함 → 지원자 경험이 **이 중 어디와 가장 비슷한지만 판단**

## 공통 원칙 (중요)
- 모든 예시는 **이력서 문단 그대로 들어가도 자연스러운 서술**
- **도구 이름보다 판단/행동/결과 중심**
- "학습/경험"만 있으면 **하**
- "운영 중 문제 → 구조/전략 변경"이 있으면 **상**

## 점수 범위
- **상**: 75~90점 (강한 상=88~90, 보통 상=80~87, 약한 상=75~79)
- **중**: 55~70점 (강한 중=67~70, 보통 중=60~66, 약한 중=55~59)
- **하**: 40~50점 (언급 있음=48~50, 약간 언급=44~47, 전혀 없음=40~43)

## 평가 원칙
- 명시적으로 언급되지 않은 KPI는 "하(40~45)" 처리
- 도구/기술 이름만 나열하면 "중(55~65)" 상한
- "문제→판단→해결→결과" 흐름이 있으면 "상(80~90)" 가능
- 학습/경험만 언급하면 "하(45~50)"
- 같은 레벨 내에서도 근거의 강도에 따라 세부 점수 차등

---

## KPI 요약표 (빠른 참조용)

| # | KPI | 상(75~90) | 중(55~70) | 하(40~50) |
|---|-----|-----------|-----------|-----------|
| 1 | 백엔드 기술 역량 | 운영환경에서 예외처리, 비동기, 구조설계까지 다룸 | 기본 구현 가능, 계층구조 따라 개발 | 튜토리얼/예제 수준 학습 |
| 2 | REST API 설계·구현 | 리소스 설계, 에러규약 통일, 구조개선 경험 | 요구사항 기반 API 구현 | 엔드포인트만 구현 |
| 3 | DB·SQL·데이터 모델링 | 인덱스 최적화, 쿼리 튜닝, 성능개선 경험 | 테이블 설계, ORM 사용 | 단일 테이블 CRUD |
| 4 | 아키텍처 설계 | 구조 재정의, 확장성/비용 트레이드오프 판단 | 레이어드 아키텍처 기반 개발 | 단일 프로젝트 구조 |
| 5 | 클라우드·DevOps 환경 이해 | 클라우드 배포+운영, 인프라 구성 직접 관리 | 클라우드 환경 배포 경험 | 로컬 환경만 |
| 6 | 성능·트래픽 처리 최적화 | 병목분석, 캐시/비동기 전략, 수치적 개선 | 성능이슈 인지하고 일부 개선 | 성능 고려 없음 |
| 7 | 보안·인증·권한 처리 | 인증/권한 흐름 설계, 보안체계 구축 | 로그인/접근제한 기본 구현 | 보안 고려 없음 |
| 8 | 테스트·코드 품질 관리 | 테스트코드 작성, 리팩토링으로 품질 유지 | 일부 테스트 또는 간단한 리팩토링 | 테스트/리팩토링 없음 |
| 9 | 협업·문서화·의사결정 기록 | 문서정리, 협업프로세스 개선, 의사결정 주도 | 필요한 부분 간단히 문서화 | 문서 없이 구두 소통 |
| 10 | 운영·모니터링·장애 대응 | 모니터링 구축, 장애분석/재발방지 | 로그 확인해서 문제 해결 | 운영 경험 없음 |

---

## KPI별 상세 예시

## 1️⃣ 백엔드 기술 역량

### 🔼 상
Spring Boot 기반 서비스에서 비즈니스 요구사항을 분석해 도메인별 책임이 분리된 구조로 기능을 구현했습니다.

운영 중 발생한 예외 상황을 반영해 코드 구조를 개선하며 안정적인 서비스 동작을 유지했습니다.

### 🔽 중
Spring Boot를 사용해 요구사항에 맞는 기능을 구현하고, 기본적인 계층 구조에 따라 개발했습니다.

### 🔻 하
Spring Boot를 학습하며 예제 프로젝트를 따라 기능을 구현해보았습니다.

---

## 2️⃣ REST API 설계·구현

### 🔼 상
서비스 기능 확장 과정에서 API 구조를 정리해 중복 엔드포인트를 통합했습니다.

에러 응답 형식을 통일하고, API 변경 사항을 팀과 공유하며 구조 개선을 진행했습니다.

### 🔽 중
요구사항에 맞춰 REST API를 구현하고 기본적인 상태 코드와 응답 형식을 사용했습니다.

### 🔻 하
API 엔드포인트를 구현해 요청을 처리하는 기능을 만들었습니다.

---

## 3️⃣ DB·SQL·데이터 모델링

### 🔼 상
서비스 요구사항에 맞춰 데이터 구조를 설계하고, 조회 패턴을 고려해 인덱스를 적용했습니다.

실제 성능 이슈를 분석해 쿼리와 구조를 개선했습니다.

### 🔽 중
테이블 구조를 설계하고 ORM을 사용해 데이터를 관리했습니다.

### 🔻 하
단일 테이블 위주로 데이터를 저장하며 CRUD 기능을 구현했습니다.

---

## 4️⃣ 아키텍처 설계

### 🔼 상
서비스 규모와 팀 상황을 고려해 구조를 설계하고, 기능별 책임을 분리해 변경 영향 범위를 줄였습니다.

성능이나 운영 이슈 발생 시 특정 영역만 개선할 수 있도록 구조를 조정했습니다.

### 🔽 중
레이어드 아키텍처를 기반으로 프로젝트를 구성하고 기능 구현을 진행했습니다.

### 🔻 하
단일 프로젝트 구조에서 기능을 추가했습니다.

---

## 5️⃣ 클라우드·DevOps

### 🔼 상
클라우드 환경에서 서비스를 배포·운영하며, 배포 흐름과 인프라 구성을 직접 관리했습니다.

운영 환경을 고려해 설정과 보안을 분리해 관리했습니다.

### 🔽 중
클라우드 환경에 서비스를 배포해 운영했습니다.

### 🔻 하
로컬 환경에서만 개발했습니다.

---

## 6️⃣ 성능·트래픽 처리 최적화

### 🔼 상
트래픽 증가로 인한 성능 저하를 분석하고 병목 지점을 개선했습니다.

캐시나 비동기 처리 전략을 적용해 응답 속도와 안정성을 개선했습니다.

### 🔽 중
성능 이슈 가능성을 인지하고 일부 코드 개선을 진행했습니다.

### 🔻 하
성능이나 트래픽을 고려하지 않고 기능을 구현했습니다.

---

## 7️⃣ 보안·인증·권한 처리

### 🔼 상
인증과 권한 흐름을 설계해 사용자 접근을 제어하고, 보안 이슈를 고려한 구조를 적용했습니다.

### 🔽 중
로그인 및 접근 제한 기능을 구현해 기본적인 보안을 적용했습니다.

### 🔻 하
인증이나 권한 처리 없이 기능을 구현했습니다.

---

## 8️⃣ 테스트·코드 품질 & 리팩토링

### 🔼 상
테스트 코드를 작성해 주요 로직을 검증하고, 리팩토링을 통해 코드 가독성과 안정성을 유지했습니다.

### 🔽 중
일부 테스트 코드를 작성하거나 간단한 리팩토링을 진행했습니다.

### 🔻 하
테스트 코드나 리팩토링 경험이 없습니다.

---

## 9️⃣ 협업·문서화·의사결정 기록

### 🔼 상
API 명세나 기술 문서를 정리해 팀과 공유했고, 논의와 결정 과정을 기록으로 남겼습니다.

협업 방식 개선을 통해 팀의 작업 효율을 높였습니다.

### 🔽 중
필요한 부분만 간단히 문서화하며 협업했습니다.

### 🔻 하
문서 없이 구두로 소통했습니다.

---

## 🔟 운영·모니터링·장애 대응

### 🔼 상
로그와 모니터링을 통해 이상 징후를 감지하고, 장애 발생 시 원인을 분석해 재발 방지 조치를 했습니다.

### 🔽 중
장애 발생 시 로그를 확인해 문제를 해결했습니다.

### 🔻 하
운영 환경 경험이 없습니다.
"""

# Few-shot 예시 (대표적인 2개)
FEW_SHOT_EXAMPLES = """
## 평가 예시

### 예시 A (운영형·성능형 백엔드)
입력:
"SW 마에스트로 과정에서 '절약 챌린지 서비스'를 주제로 팀에서 백엔드 및 인프라 개발을 맡았습니다. 방학 중 스터디로 JAVA, Spring, AWS의 핵심 이론을 익혔고, 이를 토대로 절약 챌린지 서비스에서 Spring Boot, AWS EC2/RDS, PostgreSQL 등을 활용해 주요 API 개발, 인프라, DB를 설계했습니다. 서비스 배포 후 운영하는 과정에서 다양한 문제를 마주하고, 이를 다양한 기술을 활용해 해결하는 과정에서 문제해결역량을 길렀습니다. 여기서 저는 에러율을 줄여 사용성을 높이기 위해 JAVA에서 제공하는 Sentry 라이브러리를 활용해 서버 내 API의 응답 시간이 0.8초가 초과되면 에러 메시지를 실시간으로 모니터링할 수 있도록 했습니다. 실제 에러 메시지를 통해 DB 인덱스 최적화로 응답 속도를 0.3초로 개선해 사용성을 증진시켰으며, 서비스 개선으로부터 유저가 긍정적인 리뷰를 남기기도 했습니다. 또, 이미지 로딩이 오래 걸리는 문제를 JAVA 내 이미지 라이브러리를 통해 해결했습니다. 유저가 인증한 챌린지 사진을 비동기 처리를 통해 이미지 해상도를 낮춰 DB에 저장하고 이를 제공함으로써 이미지 로딩 시간을 줄였고, 이로부터 유저 이탈률을 10% 감소시키기도 했습니다. 절약 챌린지 서비스를 운영하면서 능동적으로 협업하는 자세로 팀의 효율성을 증진시켰습니다. 앱 서비스 개발을 처음 접하는 팀원을 위해 매번 팀원의 업무에 관련된 기술 레퍼런스를 찾아 공유하여 팀원의 업무를 도왔습니다. 그뿐만 아니라 재택근무로 인해 진행 상황 및 문제 공유가 비효율적으로 이루어지는 문제를 해결하기 위해 팀 내 소통 채널 Slack을 활용해 문제 공유 게시판을 추가 개설하여, 매일 진행하는 데일리 스크럼 시간을 1시간에서 30분으로 줄였습니다."

출력:
{"1": 85, "2": 62, "3": 88, "4": 65, "5": 83, "6": 90, "7": 42, "8": 42, "9": 86, "10": 87}

근거:
- KPI 1(85): Java, Spring Boot 실전 사용, 비동기/예외처리까지 다룸 → 강한 상
- KPI 2(62): API 개발 언급되나 설계/에러규약 증거 부족 → 보통 중
- KPI 3(88): DB 인덱스 최적화 + **"0.8초→0.3초" 수치 결과 명시** → 강한 상 ⚠️ 수치 없으면 중
- KPI 4(65): EC2/RDS 구조 사용, 역할 분리는 있으나 아키텍처 판단 없음 → 보통 중
- KPI 5(83): AWS EC2/RDS, 실서비스 배포/운영 → 보통 상
- KPI 6(90): **4가지 이상**(Sentry 모니터링 + 인덱스 최적화 + 비동기 이미지 처리 + 이탈률 10% 감소) → 매우 강한 상 ⚠️ 1~2개면 중
- KPI 7(42): 인증/권한/보안 언급 없음 → 하
- KPI 8(42): 테스트/리팩토링 언급 없음 → 하
- KPI 9(86): **도구(Slack) + 사용법(문제공유 게시판 개설) + 결과(스크럼 1시간→30분)** 모두 구체적 → 강한 상 ⚠️ "팀 협업"만 있으면 중
- KPI 10(87): **실시간 도구(Sentry)** + **개선 루프(에러→분석→인덱스→성능개선)** → 강한 상 ⚠️ 로그 확인만 있으면 중

### 예시 B (아키텍처·인프라형 백엔드)
입력:
"대규모 트래픽 환경에서 안정적인 서비스를 운영하기 위해서는 애플리케이션 구현 역량뿐만 아니라, 성능·비용·안정성을 함께 고려한 인프라 수준의 판단이 중요하다고 생각합니다. 저는 서비스의 배포와 운영 과정에서 발생한 문제를 분석하고, 구조적인 해결책을 설계·적용한 경험을 보유하고 있습니다. 팀 프로젝트로 개발한 서비스를 클라우드 환경에 배포해 운영하던 중, 트래픽 증가로 인해 성능 저하와 운영 비용 증가 문제가 발생했습니다. 데이터베이스 쿼리 최적화와 캐시 전략 등 애플리케이션 레벨 개선을 시도했으나, 근본적인 한계가 있음을 인식하고 문제의 원인을 인프라 구조 관점에서 재정의했습니다. 이에 클라우드와 물리 서버 환경을 병행하는 구조로 전환하는 방안을 제안하고 실행을 주도했습니다. 서버 하드웨어를 직접 구성해 네트워크를 설계하고, 방화벽 설정을 포함한 보안 체계를 구축했으며, Docker 기반 컨테이너 배포와 모니터링 환경을 구성해 운영 안정성을 확보했습니다. 그 결과 기존 클라우드 환경 대비 운영 비용을 약 94% 절감하고, 컴퓨팅 자원을 8배 이상 확장해 트래픽 증가 상황에서도 안정적인 서비스 제공이 가능해졌습니다. 이 경험을 통해 저는 퍼블릭 클라우드의 유연성과 물리 인프라의 안정성이라는 각 환경의 특성을 이해하고, 서비스 요구사항에 맞는 아키텍처를 설계·운영할 수 있는 역량을 갖추게 되었습니다. 단순한 기능 구현을 넘어, 운영 환경과 장기적인 확장성을 고려한 기술적 의사결정을 수행하는 백엔드 엔지니어로서 기여하고자 합니다."

출력:
{"1": 85, "2": 70, "3": 78, "4": 88, "5": 90, "6": 85, "7": 70, "8": 60, "9": 75, "10": 90}

근거:
- KPI 1(85): 인프라 구성도 백엔드 역량, 서버 하드웨어 구성 + Docker + 모니터링 → 강한 상
- KPI 2(70): 직접 API 구현은 없으나 "애플리케이션 레벨 개선" 경험 언급 → 강한 중
- KPI 3(78): 쿼리 최적화, 캐시 전략 언급 + 구조적 접근 → 약한 상
- KPI 4(88): 클라우드 → 하이브리드 구조 전환, 구조 재정의 + 판단 주도, 확장성·비용·안정성 트레이드오프 → 강한 상
- KPI 5(90): 클라우드 + 물리 서버 + Docker + 네트워크 설계 → 매우 강한 상
- KPI 6(85): 트래픽 증가 문제, 구조 전환, 컴퓨팅 자원 8배 확장, 94% 비용 절감 → 강한 상
- KPI 7(70): 방화벽 설정, 보안 체계 구축 → 강한 중
- KPI 8(60): 직접 테스트 언급 없으나 운영 안정성 확보 노력 → 보통 중
- KPI 9(75): "제안하고 실행을 주도", 기술적 의사결정 수행 → 약한 상
- KPI 10(90): 모니터링 환경 구성 + 운영 비용/안정성 관리 + 수치 결과 → 매우 강한 상

### 예시 C (순수 인프라·아키텍처형 백엔드)
입력:
"서비스 운영 과정에서 트래픽 증가로 인해 응답 지연과 운영 비용 상승 문제가 발생했습니다. 초기에는 데이터베이스 쿼리 최적화와 캐시 적용 등 애플리케이션 레벨에서 해결을 시도했으나, 서비스 사용 패턴과 트래픽 특성을 고려했을 때 구조적인 한계가 있다고 판단했습니다. 이에 문제를 인프라 아키텍처 관점에서 재정의하고, 클라우드 환경과 물리 서버 환경을 병행하는 하이브리드 구조로 전환하는 방안을 제안하고 실행을 주도했습니다. 서버 하드웨어 구성부터 네트워크 설계, 방화벽 설정을 포함한 기본 보안 정책 수립까지 전반적인 인프라 구성을 담당했으며, Docker 기반 컨테이너 배포 환경을 구축해 배포 일관성을 확보했습니다. 또한 모니터링 도구를 연동해 자원 사용량과 장애 징후를 실시간으로 확인할 수 있도록 운영 환경을 개선했습니다. 그 결과 기존 대비 운영 비용을 크게 절감하면서도 트래픽 증가 상황에서도 안정적인 서비스 제공이 가능해졌습니다. 이 경험을 통해 단순 기능 구현을 넘어, 서비스 특성과 운영 환경에 맞는 구조를 설계하고 장기적인 안정성을 확보하는 백엔드 엔지니어로서의 역량을 강화할 수 있었습니다."

출력:
{"1": 80, "2": 65, "3": 70, "4": 85, "5": 88, "6": 90, "7": 42, "8": 48, "9": 70, "10": 85}

근거:
- KPI 1(80): 인프라 구성 + Docker + 서버 하드웨어도 백엔드 역량으로 인정 → 보통 상
- KPI 2(65): 직접 API 구현 없으나 "애플리케이션 레벨" 경험 언급 → 보통 중
- KPI 3(70): 쿼리 최적화, 캐시 적용 언급 → 강한 중
- KPI 4(85): 앱 레벨 → 인프라 레벨 전환, 하이브리드 구조, 구조적 재정의 + 실행 주도 → 강한 상
- KPI 5(88): 클라우드 + 물리 서버 + Docker + 네트워크 설계 → 강한 상
- KPI 6(90): 트래픽 증가 + 구조 전환 + 비용·성능 동시 개선 + 모니터링 → 매우 강한 상
- KPI 7(42): 방화벽 "기본 보안 정책" 수준, 인증/권한 체계 없음 → 하
- KPI 8(48): 테스트, 리팩토링 전혀 없음, 배포 일관성만 언급 → 하
- KPI 9(70): "제안하고 실행을 주도" + 운영 환경 개선 → 강한 중
- KPI 10(85): 모니터링 도구, 자원 사용량, 장애 징후 실시간 확인 → 강한 상

### 예시 D (실무형 주니어 백엔드)
입력:
"팀 프로젝트에서 백엔드 개발을 담당하며 서비스 기능 구현과 운영을 경험했습니다. 요구사항에 맞춰 REST API를 구현하고 ORM을 사용해 데이터베이스 테이블 구조를 설계했으며, 클라우드 환경에 서비스를 배포해 운영했습니다. 서비스 사용량이 증가하면서 특정 API의 응답 속도가 느려지는 문제가 발생했고, 팀 내 논의를 통해 조회 빈도가 높은 컬럼을 기준으로 인덱스를 추가하는 방식으로 성능을 개선했습니다. 또한 운영 중 장애가 발생했을 때 로그를 확인해 원인을 파악하고, 코드 수정이나 설정 변경을 통해 문제를 해결하는 경험을 했습니다. 클라우드 환경에서의 배포와 기본적인 인프라 설정을 경험하며 서비스 운영 흐름을 이해할 수 있었지만, 아키텍처 구조나 인프라 구성에 대한 의사결정은 주로 팀에서 정한 방향에 따라 수행했습니다. 이 경험을 통해 백엔드 개발 전반의 흐름과 실무 환경에서의 역할 수행 능력을 기를 수 있었으며, 이후 보다 주도적인 기술적 판단 역량의 필요성을 인식하게 되었습니다."

출력:
{"1": 68, "2": 65, "3": 70, "4": 58, "5": 65, "6": 75, "7": 42, "8": 42, "9": 60, "10": 70}

근거:
- KPI 1(68): REST API 구현, ORM 사용, 실서비스 개발 → 강한 중
- KPI 2(65): REST API 구현, 요구사항 기반 엔드포인트 작성 → 보통 중
- KPI 3(70): 인덱스 추가로 성능 개선, 테이블 설계 → 강한 중
- KPI 4(58): "팀에서 정한 방향에 따라 수행"이나 서비스/배치 구조 이해 있음 → 약한 중
- KPI 5(65): 클라우드 배포, 기본 인프라 설정 → 보통 중
- KPI 6(75): 인덱스 추가 + 성능 개선 + 응답 속도 문제 해결 → 약한 상
- KPI 7(42): 인증·권한·보안 설계 언급 없음 → 하
- KPI 8(42): 테스트, 리팩토링, 품질 관리 언급 없음 → 하
- KPI 9(60): "팀 내 논의", 문제 해결 협업 → 약한 중
- KPI 10(70): 로그 확인 + 장애 원인 파악 + 코드 수정으로 해결 → 강한 중

### 예시 E (학습형 주니어 백엔드)
입력:
"백엔드 개발을 처음 접하며 Spring Boot를 사용해 간단한 CRUD 기능을 구현한 경험이 있습니다. 강의 자료와 예제 코드를 참고해 컨트롤러와 서비스 로직을 작성하고, 데이터베이스와 연동해 기본적인 데이터 저장과 조회 기능을 구현했습니다. 로컬 환경에서 애플리케이션을 실행해 기능이 정상적으로 동작하는 것을 확인하며 백엔드 개발의 기본 흐름을 익혔습니다. 프로젝트를 진행하며 API 요청과 응답 구조, 데이터베이스 연동 방식에 대한 이해를 높일 수 있었지만, 성능 최적화나 아키텍처 설계, 운영 환경을 고려한 개선 작업까지는 경험하지 못했습니다. 또한 테스트 코드 작성이나 배포, 모니터링과 같은 운영 관련 작업에는 참여하지 않았습니다. 이 경험을 통해 백엔드 개발의 기초적인 개념과 구조를 학습할 수 있었으며, 이후 더 복잡한 서비스 환경에서의 개발과 운영 경험을 쌓기 위해 추가적인 학습과 프로젝트 참여가 필요하다고 느꼈습니다."

출력:
{"1": 45, "2": 45, "3": 45, "4": 45, "5": 45, "6": 45, "7": 45, "8": 45, "9": 45, "10": 45}

근거:
- 전체: 튜토리얼/예제 기반 학습 수준, 실서비스 경험 없음
- KPI 1(45): Spring Boot, CRUD, 튜토리얼·예제 기반, 실전 서비스, 예외 처리, 구조 설계 없음 → 하
- KPI 2(45): 컨트롤러 작성, 요청·응답 구조 학습, 리소스 설계, 에러 규약, 실서비스 API 없음 → 하
- KPI 3(45): 기본적인 저장·조회, 테이블 구조, 인덱스, 관계 설계 없음 → 하
- KPI 4(45): 구조 설계, 모듈화, 책임 분리 전혀 없음 → 하
- KPI 5(45): 로컬 실행만, 배포, 인프라, CI/CD 없음 → 하
- KPI 6(45): 성능, 캐시, 병목, 트래픽 언급 없음 → 하
- KPI 7(45): 전혀 없음 → 하
- KPI 8(45): 테스트 코드, 리팩토링, 품질 관리 없음 → 하
- KPI 9(45): 개인 학습, 협업·문서·의사결정 없음 → 하
- KPI 10(45): 운영·모니터링·장애 경험 없음 → 하
"""

def evaluate_resume_kpis(resume_text: str) -> Dict[int, int]:
    """
    이력서 텍스트를 LLM이 직접 평가하여 백엔드 KPI별 점수 산출.
    
    Few-shot Learning 방식으로 예시를 제공하고,
    LLM이 동일한 기준으로 새 이력서를 평가.
    
    Args:
        resume_text: 이력서/경력 텍스트
    
    Returns:
        {kpi_id: 점수} (점수는 40~90 범위의 정수)
    """
    client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    system_prompt = f"""너는 백엔드 개발자 역량 평가 전문가다.
주어진 이력서/경력 텍스트를 읽고, 10개 KPI에 대해 점수를 매긴다.

{KPI_DEFINITIONS}

{FEW_SHOT_EXAMPLES}

## 출력 형식
반드시 JSON 형식으로만 응답해. 설명 없이 점수만 출력.
{{"1": 점수, "2": 점수, ..., "10": 점수}}

## 점수 부여 규칙 (중요!)
- 상 수준: 75~90 범위에서 근거 강도에 따라 차등 (예: 강한 상=88, 보통 상=82, 약한 상=76)
- 중 수준: 55~70 범위에서 근거 강도에 따라 차등 (예: 강한 중=68, 보통 중=62, 약한 중=56)
- 하 수준: 40~50 범위에서 근거 강도에 따라 차등 (예: 약간 언급=48, 거의 없음=44, 전무=40)

## ⚠️ 과대평가 방지 규칙 (필수!)
1. "기본적인", "간단한", "단순한" 표현 → 해당 KPI 중(55~70) 상한, 절대 상 아님
2. "처음 접하며", "학습하며", "경험하지 못했" → 해당 KPI 하(40~50)
3. 인덱스 추가만 있고 수치 결과 없음 → KPI 3·6은 중(55~70) 상한
4. "팀 협업", "문서 공유" 추상적 언급만 → KPI 9는 중(55~70) 상한
5. "로그 확인", "기본 모니터링" → KPI 10은 중(55~70) 상한
"""

    user_prompt = f"""다음 이력서를 평가해줘:

{resume_text}

## 평가 전 확인사항:
2. "기본적인", "간단한" 표현이 있으면 → 해당 KPI는 중(55~70) 상한
3. "인덱스 추가"만 있고 수치(예: 0.8초→0.3초) 없으면 → KPI 3·6은 중 상한
4. "문서로 정리", "협업" 추상적 언급만 → KPI 9는 중 상한
5. "로그 정리", "기본 모니터링" → KPI 10은 중 상한

JSON 형식으로 10개 KPI 점수를 출력해."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.0,  # 일관성 최대화
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content
        scores = json.loads(result)
        
        # KPI ID를 int로 변환하고 범위 제한
        return {
            int(kpi_id): max(40, min(90, int(score))) 
            for kpi_id, score in scores.items()
        }
    
    except Exception as e:
        print(f"LLM 평가 오류: {e}")
        # 오류 시 기본값 반환
        return {i: 45 for i in range(1, 11)}
