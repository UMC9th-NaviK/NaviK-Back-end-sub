"""
LLM 기반 백엔드 KPI 직접 평가 모듈.

Few-shot Learning을 활용하여 이력서 텍스트에서 
백엔드 개발자 KPI 10개에 대한 점수를 직접 산출.
"""
from typing import Dict
from openai import OpenAI
import json

from app.core.config import settings


# KPI 정의 및 평가 기준
KPI_DEFINITIONS = """
## BE KPI 10개 및 평가 기준

아래 예시는 **"기준표"** 역할을 함 → 지원자 경험이 **이 중 어디와 가장 비슷한지만 판단**

## 공통 원칙 (중요)
- 모든 예시는 **이력서 문단 그대로 들어가도 자연스러운 서술**
- **도구 이름보다 판단/행동/결과 중심**
- "학습/경험"만 있으면 **하**
- "운영 중 문제 → 구조/전략 변경"이 있으면 **상**

## 점수 범위
- **상**: 75~90점 (강한 상=88~90, 보통 상=80~87, 약한 상=75~79)
- **중**: 55~70점 (강한 중=67~70, 보통 중=60~66, 약한 중=55~59)
- **하**: 40~50점 (언급 있음=48~50, 약간 언급=44~47, 전혀 없음=40~43)

## 평가 원칙
- 명시적으로 언급되지 않은 KPI는 "하(40~45)" 처리
- 도구/기술 이름만 나열하면 "중(55~65)" 상한
- "문제→판단→해결→결과" 흐름이 있으면 "상(80~90)" 가능
- 학습/경험만 언급하면 "하(45~50)"
- 같은 레벨 내에서도 근거의 강도에 따라 세부 점수 차등

---

## KPI 요약표 (빠른 참조용)

| # | KPI | 상(75~90) | 중(55~70) | 하(40~50) |
|---|-----|-----------|-----------|-----------|
| 1 | 주력 언어·프레임워크 숙련도 | 운영환경에서 예외처리, 비동기, 구조설계까지 다룸 | 기본 구현 가능, 계층구조 따라 개발 | 튜토리얼/예제 수준 학습 |
| 2 | REST API 설계·구현 | 리소스 설계, 에러규약 통일, 구조개선 경험 | 요구사항 기반 API 구현 | 엔드포인트만 구현 |
| 3 | DB·SQL·데이터 모델링 | 인덱스 최적화, 쿼리 튜닝, 성능개선 경험 | 테이블 설계, ORM 사용 | 단일 테이블 CRUD |
| 4 | 아키텍처 설계 | 구조 재정의, 확장성/비용 트레이드오프 판단 | 레이어드 아키텍처 기반 개발 | 단일 프로젝트 구조 |
| 5 | 클라우드·DevOps 환경 이해 | 클라우드 배포+운영, 인프라 구성 직접 관리 | 클라우드 환경 배포 경험 | 로컬 환경만 |
| 6 | 성능·트래픽 처리 최적화 | 병목분석, 캐시/비동기 전략, 수치적 개선 | 성능이슈 인지하고 일부 개선 | 성능 고려 없음 |
| 7 | 보안·인증·권한 처리 | 인증/권한 흐름 설계, 보안체계 구축 | 로그인/접근제한 기본 구현 | 보안 고려 없음 |
| 8 | 테스트·코드 품질 관리 | 테스트코드 작성, 리팩토링으로 품질 유지 | 일부 테스트 또는 간단한 리팩토링 | 테스트/리팩토링 없음 |
| 9 | 협업·문서화·의사결정 기록 | 문서정리, 협업프로세스 개선, 의사결정 주도 | 필요한 부분 간단히 문서화 | 문서 없이 구두 소통 |
| 10 | 운영·모니터링·장애 대응 | 모니터링 구축, 장애분석/재발방지 | 로그 확인해서 문제 해결 | 운영 경험 없음 |

---

## KPI별 상세 예시

## 1️⃣ 주력 언어·프레임워크 숙련도

### 🔼 상
Spring Boot 기반 서비스에서 비즈니스 요구사항을 분석해 도메인별 책임이 분리된 구조로 기능을 구현했습니다.

운영 중 발생한 예외 상황을 반영해 코드 구조를 개선하며 안정적인 서비스 동작을 유지했습니다.

### 🔽 중
Spring Boot를 사용해 요구사항에 맞는 기능을 구현하고, 기본적인 계층 구조에 따라 개발했습니다.

### 🔻 하
Spring Boot를 학습하며 예제 프로젝트를 따라 기능을 구현해보았습니다.

---

## 2️⃣ REST API 설계·구현

### 🔼 상
서비스 기능 확장 과정에서 API 구조를 정리해 중복 엔드포인트를 통합했습니다.

에러 응답 형식을 통일하고, API 변경 사항을 팀과 공유하며 구조 개선을 진행했습니다.

### 🔽 중
요구사항에 맞춰 REST API를 구현하고 기본적인 상태 코드와 응답 형식을 사용했습니다.

### 🔻 하
API 엔드포인트를 구현해 요청을 처리하는 기능을 만들었습니다.

---

## 3️⃣ DB·SQL·데이터 모델링

### 🔼 상
서비스 요구사항에 맞춰 데이터 구조를 설계하고, 조회 패턴을 고려해 인덱스를 적용했습니다.

실제 성능 이슈를 분석해 쿼리와 구조를 개선했습니다.

### 🔽 중
테이블 구조를 설계하고 ORM을 사용해 데이터를 관리했습니다.

### 🔻 하
단일 테이블 위주로 데이터를 저장하며 CRUD 기능을 구현했습니다.

---

## 4️⃣ 아키텍처 설계

### 🔼 상
서비스 규모와 팀 상황을 고려해 구조를 설계하고, 기능별 책임을 분리해 변경 영향 범위를 줄였습니다.

성능이나 운영 이슈 발생 시 특정 영역만 개선할 수 있도록 구조를 조정했습니다.

### 🔽 중
레이어드 아키텍처를 기반으로 프로젝트를 구성하고 기능 구현을 진행했습니다.

### 🔻 하
단일 프로젝트 구조에서 기능을 추가했습니다.

---

## 5️⃣ 클라우드·DevOps

### 🔼 상
클라우드 환경에서 서비스를 배포·운영하며, 배포 흐름과 인프라 구성을 직접 관리했습니다.

운영 환경을 고려해 설정과 보안을 분리해 관리했습니다.

### 🔽 중
클라우드 환경에 서비스를 배포해 운영했습니다.

### 🔻 하
로컬 환경에서만 개발했습니다.

---

## 6️⃣ 성능·트래픽 처리 최적화

### 🔼 상
트래픽 증가로 인한 성능 저하를 분석하고 병목 지점을 개선했습니다.

캐시나 비동기 처리 전략을 적용해 응답 속도와 안정성을 개선했습니다.

### 🔽 중
성능 이슈 가능성을 인지하고 일부 코드 개선을 진행했습니다.

### 🔻 하
성능이나 트래픽을 고려하지 않고 기능을 구현했습니다.

---

## 7️⃣ 보안·인증·권한 처리

### 🔼 상
인증과 권한 흐름을 설계해 사용자 접근을 제어하고, 보안 이슈를 고려한 구조를 적용했습니다.

### 🔽 중
로그인 및 접근 제한 기능을 구현해 기본적인 보안을 적용했습니다.

### 🔻 하
인증이나 권한 처리 없이 기능을 구현했습니다.

---

## 8️⃣ 테스트·코드 품질 & 리팩토링

### 🔼 상
테스트 코드를 작성해 주요 로직을 검증하고, 리팩토링을 통해 코드 가독성과 안정성을 유지했습니다.

### 🔽 중
일부 테스트 코드를 작성하거나 간단한 리팩토링을 진행했습니다.

### 🔻 하
테스트 코드나 리팩토링 경험이 없습니다.

---

## 9️⃣ 협업·문서화·의사결정 기록

### 🔼 상
API 명세나 기술 문서를 정리해 팀과 공유했고, 논의와 결정 과정을 기록으로 남겼습니다.

협업 방식 개선을 통해 팀의 작업 효율을 높였습니다.

### 🔽 중
필요한 부분만 간단히 문서화하며 협업했습니다.

### 🔻 하
문서 없이 구두로 소통했습니다.

---

## 🔟 운영·모니터링·장애 대응

### 🔼 상
로그와 모니터링을 통해 이상 징후를 감지하고, 장애 발생 시 원인을 분석해 재발 방지 조치를 했습니다.

### 🔽 중
장애 발생 시 로그를 확인해 문제를 해결했습니다.

### 🔻 하
운영 환경 경험이 없습니다.
"""

# Few-shot 예시 (대표적인 2개)
FEW_SHOT_EXAMPLES = """
## 평가 예시

### 예시 A (운영형·성능형 백엔드)
입력:
"SW 마에스트로 과정에서 '절약 챌린지 서비스'를 주제로 팀에서 백엔드 및 인프라 개발을 맡았습니다. 방학 중 스터디로 JAVA, Spring, AWS의 핵심 이론을 익혔고, 이를 토대로 절약 챌린지 서비스에서 Spring Boot, AWS EC2/RDS, PostgreSQL 등을 활용해 주요 API 개발, 인프라, DB를 설계했습니다. 서비스 배포 후 운영하는 과정에서 다양한 문제를 마주하고, 이를 다양한 기술을 활용해 해결하는 과정에서 문제해결역량을 길렀습니다. 여기서 저는 에러율을 줄여 사용성을 높이기 위해 JAVA에서 제공하는 Sentry 라이브러리를 활용해 서버 내 API의 응답 시간이 0.8초가 초과되면 에러 메시지를 실시간으로 모니터링할 수 있도록 했습니다. 실제 에러 메시지를 통해 DB 인덱스 최적화로 응답 속도를 0.3초로 개선해 사용성을 증진시켰으며, 서비스 개선으로부터 유저가 긍정적인 리뷰를 남기기도 했습니다. 또, 이미지 로딩이 오래 걸리는 문제를 JAVA 내 이미지 라이브러리를 통해 해결했습니다. 유저가 인증한 챌린지 사진을 비동기 처리를 통해 이미지 해상도를 낮춰 DB에 저장하고 이를 제공함으로써 이미지 로딩 시간을 줄였고, 이로부터 유저 이탈률을 10% 감소시키기도 했습니다. 절약 챌린지 서비스를 운영하면서 능동적으로 협업하는 자세로 팀의 효율성을 증진시켰습니다. 앱 서비스 개발을 처음 접하는 팀원을 위해 매번 팀원의 업무에 관련된 기술 레퍼런스를 찾아 공유하여 팀원의 업무를 도왔습니다. 그뿐만 아니라 재택근무로 인해 진행 상황 및 문제 공유가 비효율적으로 이루어지는 문제를 해결하기 위해 팀 내 소통 채널 Slack을 활용해 문제 공유 게시판을 추가 개설하여, 매일 진행하는 데일리 스크럼 시간을 1시간에서 30분으로 줄였습니다."

출력:
{"1": 85, "2": 62, "3": 88, "4": 65, "5": 83, "6": 90, "7": 42, "8": 42, "9": 86, "10": 87}

근거:
- KPI 1(85): Java, Spring Boot 실전 사용, 비동기/예외처리까지 다룸 → 강한 상
- KPI 2(62): API 개발 언급되나 설계/에러규약 증거 부족 → 보통 중
- KPI 3(88): DB 인덱스 최적화, 응답속도 0.8→0.3초 개선, 수치 명시 → 강한 상
- KPI 4(65): EC2/RDS 구조 사용, 역할 분리는 있으나 아키텍처 판단 없음 → 보통 중
- KPI 5(83): AWS EC2/RDS, 실서비스 배포/운영 → 보통 상
- KPI 6(90): Sentry 모니터링, DB 인덱스 최적화, 비동기 이미지 처리, 이탈률 10% 감소 → 매우 강한 상
- KPI 7(42): 인증/권한/보안 언급 없음 → 하
- KPI 8(42): 테스트/리팩토링 언급 없음 → 하
- KPI 9(86): Slack 문제공유 게시판, 레퍼런스 공유, 스크럼 시간 단축 → 강한 상
- KPI 10(87): Sentry 실시간 모니터링, 에러→DB인덱스→성능개선 루프 → 강한 상

### 예시 B (학습형 주니어)
입력:
"백엔드 개발을 처음 접하며 Spring Boot를 사용해 간단한 CRUD 기능을 구현한 경험이 있습니다. 강의 자료와 예제 코드를 참고해 컨트롤러와 서비스 로직을 작성하고, 데이터베이스와 연동해 기본적인 데이터 저장과 조회 기능을 구현했습니다. 로컬 환경에서 애플리케이션을 실행해 기능이 정상적으로 동작하는 것을 확인하며 백엔드 개발의 기본 흐름을 익혔습니다. 프로젝트를 진행하며 API 요청과 응답 구조, 데이터베이스 연동 방식에 대한 이해를 높일 수 있었지만, 성능 최적화나 아키텍처 설계, 운영 환경을 고려한 개선 작업까지는 경험하지 못했습니다. 또한 테스트 코드 작성이나 배포, 모니터링과 같은 운영 관련 작업에는 참여하지 않았습니다."

출력:
{"1": 48, "2": 46, "3": 45, "4": 42, "5": 40, "6": 40, "7": 40, "8": 40, "9": 42, "10": 40}

근거:
- 전체: 튜토리얼/예제 기반 학습 수준, 실서비스 경험 없음
- KPI 1(48): Spring Boot 사용 언급은 있음 → 약간 높은 하
- KPI 2(46): API 요청/응답 구조 이해 언급 → 약간 높은 하
- 나머지: 본인이 "성능/아키텍처/테스트/배포/모니터링 경험 없음"을 명시 → 낮은 하
"""


def evaluate_resume_kpis(resume_text: str) -> Dict[int, int]:
    """
    이력서 텍스트를 LLM이 직접 평가하여 백엔드 KPI별 점수 산출.
    
    Few-shot Learning 방식으로 예시를 제공하고,
    LLM이 동일한 기준으로 새 이력서를 평가.
    
    Args:
        resume_text: 이력서/경력 텍스트
    
    Returns:
        {kpi_id: 점수} (점수는 40~90 범위의 정수)
    """
    client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    system_prompt = f"""너는 백엔드 개발자 역량 평가 전문가다.
주어진 이력서/경력 텍스트를 읽고, 10개 KPI에 대해 점수를 매긴다.

{KPI_DEFINITIONS}

{FEW_SHOT_EXAMPLES}

## 출력 형식
반드시 JSON 형식으로만 응답해. 설명 없이 점수만 출력.
{{"1": 점수, "2": 점수, ..., "10": 점수}}

## 점수 부여 규칙 (중요!)
- 상 수준: 75~90 범위에서 근거 강도에 따라 차등 (예: 강한 상=88, 보통 상=82, 약한 상=76)
- 중 수준: 55~70 범위에서 근거 강도에 따라 차등 (예: 강한 중=68, 보통 중=62, 약한 중=56)
- 하 수준: 40~50 범위에서 근거 강도에 따라 차등 (예: 약간 언급=48, 거의 없음=44, 전무=40)

절대 45, 65, 85로 딱 떨어지게 점수를 매기지 마라. 반드시 범위 내에서 세밀하게 차등을 두어라.
"""

    user_prompt = f"""다음 이력서를 평가해줘:

{resume_text}

JSON 형식으로 10개 KPI 점수를 출력해."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,  # 약간의 변동성 허용
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content
        scores = json.loads(result)
        
        # KPI ID를 int로 변환하고 범위 제한
        return {
            int(kpi_id): max(40, min(90, int(score))) 
            for kpi_id, score in scores.items()
        }
    
    except Exception as e:
        print(f"LLM 평가 오류: {e}")
        # 오류 시 기본값 반환
        return {i: 45 for i in range(1, 11)}
