"""
LLM 기반 프론트엔드 KPI 직접 평가 모듈.

Few-shot Learning을 활용하여 이력서 텍스트에서 
프론트엔드 개발자 KPI 10개에 대한 점수를 직접 산출.
"""
from typing import Dict
from openai import OpenAI
import json

from app.core.config import settings


# KPI 정의 및 평가 기준
KPI_DEFINITIONS = """
## FE KPI 10개 및 평가 기준

아래 예시는 **"기준표"** 역할을 함 → 지원자 경험이 **이 중 어디와 가장 비슷한지만 판단**

## 공통 원칙 (중요)
- 모든 예시는 **이력서 문단 그대로 들어가도 자연스러운 서술**
- **도구 이름보다 판단/행동/결과 중심**
- "학습/경험"만 있으면 **하**
- "운영 중 문제 → 구조/전략 변경"이 있으면 **상**

## 점수 범위
- **상**: 75~90점 (강한 상=88~90, 보통 상=80~87, 약한 상=75~79)
- **중**: 55~70점 (강한 중=67~70, 보통 중=60~66, 약한 중=55~59)
- **하**: 40~50점 (언급 있음=48~50, 약간 언급=44~47, 전혀 없음=40~43)

## 평가 원칙
- 명시적으로 언급되지 않은 KPI는 "하(40~45)" 처리
- 도구/기술 이름만 나열하면 "중(55~65)" 상한
- "문제→판단→해결→결과" 흐름이 있으면 "상(80~90)" 가능
- 학습/경험만 언급하면 "하(45~50)"
- 같은 레벨 내에서도 근거의 강도에 따라 세부 점수 차등

---

## KPI 요약표 (빠른 참조용)

| # | KPI | 상(75~90) | 중(55~70) | 하(40~50) |
|---|-----|-----------|-----------|-----------|
| 1 | 웹 기본기(HTML/CSS/JS/TS) | DOM 조작, 반응형, 비동기 처리 등 기본기 탄탄, 실전 활용 | 기본 문법 이해, 간단한 기능 구현 | 튜토리얼/예제 수준 학습 |
| 2 | 프레임워크 숙련도(React/Vue/TS) | 컴포넌트 구조, SSR/CSR, Hooks 등 깊이 있게 이해 | 기본 컴포넌트 작성, 상태 관리 사용 | 예제 따라하기 수준 |
| 3 | 상태관리·컴포넌트 아키텍처 | 재사용·확장 고려한 컴포넌트 설계, 상태 분리 전략 | 기본적인 컴포넌트 분리 | 단일 컴포넌트 구조 |
| 4 | 웹 성능 최적화(LCP·CLS) | 지표 기반 병목 분석, 로딩/인터랙션 경험 개선, 수치적 결과 | 성능 이슈 인지하고 일부 개선 | 성능 고려 없음 |
| 5 | API 연동·비동기 처리 | 에러 핸들링, 로딩 처리, 캐싱 전략까지 고려 | 기본 API 호출 구현 | API 연동 경험 없음 |
| 6 | 반응형·크로스 브라우징 대응 | 다양한 디바이스/브라우저 환경에서 일관된 동작 | 기본 반응형 구현 | 반응형/크로스브라우징 고려 없음 |
| 7 | 테스트 코드·품질 관리 | 유닛/통합 테스트, 린트, 타입 안정성 유지 | 일부 테스트 또는 간단한 린트 | 테스트/품질 관리 없음 |
| 8 | Git·PR·협업 프로세스 이해 | 코드 리뷰, PR 규칙, Gitflow 등 협업 프로세스 이해 | 기본 Git 사용 | Git/협업 경험 없음 |
| 9 | 사용자 중심 UI 개발(UX 연계) | 디자인 의도 이해, 사용성/인터랙션 고려한 구현 | 디자인 시안 따라 구현 | 사용성 고려 없음 |
| 10 | 빌드·도구 환경(Vite/Webpack) | 번들링 이해, 프로젝트 규모에 맞는 도구 선택·관리 | 기본 빌드 도구 사용 | 빌드 도구 경험 없음 |

---

## KPI별 상세 예시

## 1️⃣ 웹 기본기 (HTML/CSS/JS/TS)

### 🔼 상
DOM 구조와 렌더링 흐름을 고려해 마크업을 설계하고, 비동기 처리 과정에서 발생하는 상태 변화와 이벤트 흐름을 안정적으로 제어했습니다. 타입을 활용해 런타임 오류를 줄이고, 웹 동작 원리를 이해한 구현을 수행했습니다.

### 🔽 중
HTML/CSS/JavaScript를 사용해 화면과 기능을 구현하고, 비동기 요청을 처리했습니다.

### 🔻 하
예제와 자료를 참고해 화면과 기능을 구현했습니다.

---

## 2️⃣ 프레임워크 숙련도 (React/Vue/TS)

### 🔼 상
컴포넌트 책임을 분리해 구조를 설계하고, 상태와 사이드 이펙트를 적절히 관리했습니다. 프레임워크 특성을 고려해 CSR/SSR 환경에서의 동작 차이를 이해하고 구현했습니다.

### 🔽 중
프레임워크를 사용해 컴포넌트 기반으로 화면을 구현했습니다.

### 🔻 하
프레임워크 문법을 따라 기능을 구현했습니다.

---

## 3️⃣ 상태관리·컴포넌트 아키텍처

### 🔼 상
전역 상태와 로컬 상태를 역할에 맞게 분리하고, 재사용 가능한 컴포넌트 구조를 설계해 확장성과 유지보수성을 확보했습니다.

### 🔽 중
상태 관리를 적용해 컴포넌트 간 데이터 전달을 처리했습니다.

### 🔻 하
props를 통해 필요한 데이터를 전달했습니다.

---

## 4️⃣ 웹 성능 최적화 (LCP·CLS)

### 🔼 상
Lighthouse 지표를 기준으로 성능 병목을 분석하고, 이미지 최적화·코드 스플리팅 등을 적용해 LCP와 CLS를 개선했습니다.

### 🔽 중
성능 이슈를 인지하고 일부 최적화를 적용했습니다.

### 🔻 하
성능 지표를 고려하지 않고 구현했습니다.

---

## 5️⃣ API 연동 & 비동기 처리

### 🔼 상
API 호출 흐름을 설계하고, 로딩·에러·캐싱 상태를 분리해 사용자 경험을 안정적으로 구성했습니다.

### 🔽 중
API를 호출해 데이터를 화면에 표시하고 에러를 처리했습니다.

### 🔻 하
API를 호출해 데이터를 받아왔습니다.

---

## 6️⃣ 반응형·크로스 브라우징 대응

### 🔼 상
다양한 디바이스와 브라우저 환경을 고려해 반응형 레이아웃을 설계하고, 환경별 이슈를 사전에 대응했습니다.

### 🔽 중
반응형 레이아웃을 적용했습니다.

### 🔻 하
특정 해상도 기준으로만 구현했습니다.

---

## 7️⃣ 테스트 코드·품질 관리

### 🔼 상
주요 로직에 대해 테스트 코드를 작성하고, 린트·타입 체크를 통해 코드 품질을 지속적으로 관리했습니다.

### 🔽 중
일부 테스트나 린트 규칙을 적용했습니다.

### 🔻 하
테스트나 품질 관리 도구를 사용하지 않았습니다.

---

## 8️⃣ Git·PR·협업 프로세스 이해

### 🔼 상
PR 기반 협업 과정에서 코드 리뷰를 주고받으며, 팀 규칙에 맞춰 변경 이력을 관리했습니다.

### 🔽 중
Git을 사용해 협업하며 PR을 경험했습니다.

### 🔻 하
개인 브랜치에서만 작업했습니다.

---

## 9️⃣ 사용자 중심 UI 개발 (UX 연계)

### 🔼 상
디자인 의도를 이해하고, 실제 사용 흐름을 고려해 인터랙션과 UI를 개선했습니다. 사용자 피드백을 반영해 사용성을 개선했습니다.

### 🔽 중
디자인 시안을 기준으로 UI를 구현했습니다.

### 🔻 하
주어진 화면을 그대로 구현했습니다.

---

## 🔟 빌드·도구 환경 (Vite/Webpack)

### 🔼 상
프로젝트 규모에 맞춰 빌드 도구를 설정하고, 번들링 전략을 조정해 개발·배포 효율을 개선했습니다.

### 🔽 중
기존 설정을 사용해 프로젝트를 구성했습니다.

### 🔻 하
빌드 도구 설정을 다뤄본 적이 없습니다.
"""

# Few-shot 예시 (대표적인 2개)
FEW_SHOT_EXAMPLES = """
## 평가 예시

### 예시 A (성능 최적화 중심 프론트엔드)
입력:
"React와 TypeScript를 활용한 대시보드 프로젝트에서 프론트엔드 개발을 담당했습니다. 초기에는 모든 데이터를 한 번에 로드해 초기 로딩 시간이 3초 이상 걸리는 문제가 발생했습니다. Lighthouse 성능 점수가 45점으로 낮게 나왔고, 특히 LCP(Largest Contentful Paint)가 4.2초로 매우 느렸습니다. 이를 개선하기 위해 React Query를 도입해 데이터 캐싱과 무한 스크롤을 구현했고, 이미지 최적화를 위해 WebP 포맷과 lazy loading을 적용했습니다. 또한 코드 스플리팅을 통해 초기 번들 크기를 40% 줄였습니다. 그 결과 LCP를 1.2초로 개선했고, Lighthouse 점수를 85점까지 올릴 수 있었습니다. 컴포넌트 구조는 재사용성을 고려해 Atomic Design 패턴을 적용했고, Context API와 Zustand를 조합해 전역 상태와 지역 상태를 적절히 분리했습니다. Jest와 React Testing Library를 사용해 주요 컴포넌트에 대한 테스트 코드를 작성했고, ESLint와 Prettier를 설정해 코드 품질을 유지했습니다. Git Flow를 따라 feature 브랜치에서 개발하고, PR을 통해 코드 리뷰를 받으며 협업했습니다."

출력:
{"1": 82, "2": 88, "3": 85, "4": 90, "5": 87, "6": 75, "7": 83, "8": 78, "9": 72, "10": 80}

근거:
- KPI 1(82): TypeScript, React 활용, DOM/비동기 처리 이해 → 보통 상
- KPI 2(88): React, TypeScript 깊이 있게 사용, 코드 스플리팅 등 고급 기법 → 강한 상
- KPI 3(85): Atomic Design, Context API/Zustand 조합, 상태 분리 전략 → 강한 상
- KPI 4(90): Lighthouse 점수 45→85, LCP 4.2→1.2초, 수치적 개선 명시 → 매우 강한 상
- KPI 5(87): React Query, 캐싱, 무한 스크롤 구현 → 강한 상
- KPI 6(75): 반응형/크로스브라우징 언급 없으나 기본 대응 가능성 → 약한 상
- KPI 7(83): Jest, React Testing Library, ESLint, Prettier 설정 → 강한 상
- KPI 8(78): Git Flow, PR, 코드 리뷰 경험 → 보통 상
- KPI 9(72): 사용자 경험 개선 언급은 있으나 UX 연계 증거 부족 → 약한 상
- KPI 10(80): 코드 스플리팅, 번들 최적화 이해 → 보통 상

### 예시 B (학습형 주니어)
입력:
"프론트엔드 개발을 처음 접하며 React를 사용해 간단한 투두리스트 애플리케이션을 만들었습니다. 강의 자료를 참고해 컴포넌트를 작성하고, useState를 사용해 상태를 관리했습니다. API를 호출해 데이터를 가져오는 기능을 구현했고, CSS를 사용해 기본적인 스타일링을 적용했습니다. 로컬 환경에서 개발하고, npm을 사용해 패키지를 설치했습니다. 프로젝트를 진행하며 React의 기본 개념과 컴포넌트 구조에 대한 이해를 높일 수 있었지만, 성능 최적화나 테스트 코드 작성, 빌드 도구 설정까지는 경험하지 못했습니다."

출력:
{"1": 48, "2": 50, "3": 42, "4": 40, "5": 46, "6": 40, "7": 40, "8": 40, "9": 42, "10": 44}

근거:
- 전체: 튜토리얼/예제 기반 학습 수준, 실서비스 경험 없음
- KPI 1(48): React, CSS 사용 언급은 있음 → 약간 높은 하
- KPI 2(50): useState 사용, 기본 컴포넌트 작성 → 약간 높은 하
- KPI 3(42): 상태 관리 언급은 있으나 구조 설계 없음 → 낮은 하
- KPI 4(40): 성능 최적화 경험 없음을 명시 → 전무
- KPI 5(46): API 호출 구현 언급 → 약간 높은 하
- KPI 6(40): 반응형/크로스브라우징 언급 없음 → 전무
- KPI 7(40): 테스트 코드 경험 없음을 명시 → 전무
- KPI 8(40): Git/협업 언급 없음 → 전무
- KPI 9(42): 기본 스타일링만, 사용성 고려 없음 → 낮은 하
- KPI 10(44): npm 사용 언급은 있으나 빌드 도구 이해 없음 → 약간 높은 하
"""


def evaluate_resume_kpis(resume_text: str) -> Dict[int, int]:
    """
    이력서 텍스트를 LLM이 직접 평가하여 프론트엔드 KPI별 점수 산출.
    
    Few-shot Learning 방식으로 예시를 제공하고,
    LLM이 동일한 기준으로 새 이력서를 평가.
    
    Args:
        resume_text: 이력서/경력 텍스트
    
    Returns:
        {kpi_id: 점수} (점수는 40~90 범위의 정수)
    """
    client = OpenAI(api_key=settings.OPENAI_API_KEY)
    
    system_prompt = f"""너는 프론트엔드 개발자 역량 평가 전문가다.
주어진 이력서/경력 텍스트를 읽고, 10개 KPI에 대해 점수를 매긴다.

{KPI_DEFINITIONS}

{FEW_SHOT_EXAMPLES}

## 출력 형식
반드시 JSON 형식으로만 응답해. 설명 없이 점수만 출력.
{{"1": 점수, "2": 점수, ..., "10": 점수}}

## 점수 부여 규칙 (중요!)
- 상 수준: 75~90 범위에서 근거 강도에 따라 차등 (예: 강한 상=88, 보통 상=82, 약한 상=76)
- 중 수준: 55~70 범위에서 근거 강도에 따라 차등 (예: 강한 중=68, 보통 중=62, 약한 중=56)
- 하 수준: 40~50 범위에서 근거 강도에 따라 차등 (예: 약간 언급=48, 거의 없음=44, 전무=40)

절대 45, 65, 85로 딱 떨어지게 점수를 매기지 마라. 반드시 범위 내에서 세밀하게 차등을 두어라.
"""

    user_prompt = f"""다음 이력서를 평가해줘:

{resume_text}

JSON 형식으로 10개 KPI 점수를 출력해."""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,  # 약간의 변동성 허용
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content
        scores = json.loads(result)
        
        # KPI ID를 int로 변환하고 범위 제한
        return {
            int(kpi_id): max(40, min(90, int(score))) 
            for kpi_id, score in scores.items()
        }
    
    except Exception as e:
        print(f"LLM 평가 오류: {e}")
        # 오류 시 기본값 반환
        return {i: 45 for i in range(1, 11)}
